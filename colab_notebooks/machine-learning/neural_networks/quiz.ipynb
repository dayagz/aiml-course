{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBziscK6jg1S",
    "outputId": "9aac4758-b140-4ace-8d6c-17b6d1ca2bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.24.1 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Installing the libraries with the specified version.\n",
    "!pip install tensorflow==2.15.0 scikit-learn==1.2.2 seaborn==0.13.1 matplotlib==3.7.1 numpy==1.24.1 pandas==1.5.3 -q --user --no-warn-script-location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDm41YNRbs6e"
   },
   "source": [
    "Note: After running the above cell, kindly restart the notebook kernel and run all cells sequentially from the start again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "5Eb6RdZy7qf9"
   },
   "outputs": [],
   "source": [
    "# Libraries to help with reading and manipulating data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Libraries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Removes the limit for the number of displayed columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Sets the limit for the number of displayed rows\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "# to split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,f1_score,precision_score\n",
    "\n",
    "import tensorflow as tf #An end-to-end open source machine learning platform\n",
    "from tensorflow import keras  # High-level neural networks API for deep learning.\n",
    "from keras import backend   # Abstraction layer for neural network backend engines.\n",
    "from keras.models import Sequential  # Model for building NN sequentially.\n",
    "from keras.layers import Dense,Dropout,BatchNormalization   # for creating fully connected neural network layers.\n",
    "# to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eauLFw-P65x6"
   },
   "outputs": [],
   "source": [
    "# Set the seed using keras.utils.set_random_seed. This will set:\n",
    "# 1) `numpy` seed\n",
    "# 2) backend random seed\n",
    "# 3) `python` random seed\n",
    "keras.utils.set_random_seed(812)\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
    "# but it will affect the overall performance, so be mindful of that.\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxhpZv9y-qTw"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NVyQWHugthFQ"
   },
   "outputs": [],
   "source": [
    "# uncomment and run the following lines in case Google Colab is being used\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TV-aehaf7qf_"
   },
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "data = pd.read_csv(\"new_preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ruS1OQwB_fX"
   },
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlzqMR1K-qTz"
   },
   "source": [
    "### Displaying the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "aNvXgPEhWaLv",
    "outputId": "07e19ace-bd7c-49b8-9fcc-47c6759a0e31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "      <th>Principal</th>\n",
       "      <th>age</th>\n",
       "      <th>education_Bechalor</th>\n",
       "      <th>education_High School or Below</th>\n",
       "      <th>education_Master or Above</th>\n",
       "      <th>education_college</th>\n",
       "      <th>Gender_female</th>\n",
       "      <th>Gender_male</th>\n",
       "      <th>terms_7</th>\n",
       "      <th>terms_15</th>\n",
       "      <th>terms_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_status  Principal  age  education_Bechalor  \\\n",
       "0            0       1000   45                   0   \n",
       "1            0       1000   50                   1   \n",
       "2            0       1000   33                   1   \n",
       "3            0       1000   27                   0   \n",
       "4            0       1000   28                   0   \n",
       "\n",
       "   education_High School or Below  education_Master or Above  \\\n",
       "0                               1                          0   \n",
       "1                               0                          0   \n",
       "2                               0                          0   \n",
       "3                               0                          0   \n",
       "4                               0                          0   \n",
       "\n",
       "   education_college  Gender_female  Gender_male  terms_7  terms_15  terms_30  \n",
       "0                  0              0            1        0         0         1  \n",
       "1                  0              1            0        0         0         1  \n",
       "2                  0              1            0        0         0         1  \n",
       "3                  1              0            1        0         1         0  \n",
       "4                  1              1            0        0         0         1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['loan_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=data, x='age');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"loan_status\"], axis=1)\n",
    "y = data[\"loan_status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the neural network\n",
    "model = Sequential()\n",
    "dropout_rate=0.2\n",
    "model.add(Dense(64,activation='relu',input_dim = x_train.shape[1]))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "batch_size = x_train.shape[0]\n",
    "epochs = 20\n",
    "adam_optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam_optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 39.5034 - accuracy: 0.4625 - val_loss: 26.6332 - val_accuracy: 0.6375\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 37.3323 - accuracy: 0.4437 - val_loss: 25.0140 - val_accuracy: 0.6375\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 35.5375 - accuracy: 0.4750 - val_loss: 22.8931 - val_accuracy: 0.6375\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 32.6844 - accuracy: 0.4375 - val_loss: 21.2509 - val_accuracy: 0.6375\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 27.8801 - accuracy: 0.5031 - val_loss: 19.0234 - val_accuracy: 0.6375\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 31.2963 - accuracy: 0.4031 - val_loss: 16.3907 - val_accuracy: 0.6375\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 31.2130 - accuracy: 0.4219 - val_loss: 14.2001 - val_accuracy: 0.6375\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 31.2002 - accuracy: 0.3875 - val_loss: 12.7248 - val_accuracy: 0.6375\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 26.0278 - accuracy: 0.4500 - val_loss: 11.8454 - val_accuracy: 0.6375\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 29.6730 - accuracy: 0.4062 - val_loss: 11.8067 - val_accuracy: 0.6375\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 28.9343 - accuracy: 0.3969 - val_loss: 12.0505 - val_accuracy: 0.6375\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 28.0310 - accuracy: 0.4219 - val_loss: 12.3971 - val_accuracy: 0.6375\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 26.1845 - accuracy: 0.4250 - val_loss: 12.5876 - val_accuracy: 0.6375\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 24.9859 - accuracy: 0.4344 - val_loss: 12.5326 - val_accuracy: 0.6375\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 22.0723 - accuracy: 0.4062 - val_loss: 12.4939 - val_accuracy: 0.6375\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 25.0949 - accuracy: 0.4688 - val_loss: 12.1216 - val_accuracy: 0.6375\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 23.3235 - accuracy: 0.4250 - val_loss: 11.7513 - val_accuracy: 0.6375\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 22.9869 - accuracy: 0.4750 - val_loss: 11.2211 - val_accuracy: 0.6375\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 22.6123 - accuracy: 0.4969 - val_loss: 10.4638 - val_accuracy: 0.6375\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 20.8791 - accuracy: 0.4906 - val_loss: 9.5252 - val_accuracy: 0.6375\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val,y_val) , batch_size=batch_size, epochs=epochs)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 847us/step\n",
      "4/4 [==============================] - 0s 637us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6754966887417219"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict probabilities for test set\n",
    "y_test_cat = keras.utils.to_categorical(y_test, 3)\n",
    "y_pred = model.predict(x_test)\n",
    "# predict crisp classes for test set\n",
    "#yhat_classes = model.predict_classes(x_test)\n",
    "y_pred_probabilities = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "f1_scores = f1_score(y_test, y_pred, average=None)  # Get F1 for ALL classes\n",
    "f1_scores[0] \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the neural network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128,activation='relu',input_dim = x_train.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64,activation=\"relu\"))\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "adam_optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam_optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 1.7290 - accuracy: 0.1750 - val_loss: 1.2477 - val_accuracy: 0.1875\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.4640 - accuracy: 0.2156 - val_loss: 1.0360 - val_accuracy: 0.6500\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.3214 - accuracy: 0.2219 - val_loss: 0.9851 - val_accuracy: 0.6375\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.2014 - accuracy: 0.2875 - val_loss: 0.9657 - val_accuracy: 0.6375\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1237 - accuracy: 0.3656 - val_loss: 0.9690 - val_accuracy: 0.6375\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.1011 - accuracy: 0.4313 - val_loss: 0.9820 - val_accuracy: 0.6375\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0203 - accuracy: 0.5437 - val_loss: 0.9899 - val_accuracy: 0.6375\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9975 - accuracy: 0.5688 - val_loss: 0.9924 - val_accuracy: 0.6375\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9540 - accuracy: 0.5813 - val_loss: 0.9904 - val_accuracy: 0.6375\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9600 - accuracy: 0.6250 - val_loss: 0.9913 - val_accuracy: 0.6375\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9656 - accuracy: 0.5969 - val_loss: 0.9889 - val_accuracy: 0.6375\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9383 - accuracy: 0.6125 - val_loss: 0.9841 - val_accuracy: 0.6375\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9602 - accuracy: 0.6250 - val_loss: 0.9730 - val_accuracy: 0.6375\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9765 - accuracy: 0.6125 - val_loss: 0.9647 - val_accuracy: 0.6375\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9741 - accuracy: 0.6156 - val_loss: 0.9547 - val_accuracy: 0.6375\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9565 - accuracy: 0.6156 - val_loss: 0.9441 - val_accuracy: 0.6375\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9516 - accuracy: 0.6187 - val_loss: 0.9367 - val_accuracy: 0.6375\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9879 - accuracy: 0.6094 - val_loss: 0.9320 - val_accuracy: 0.6375\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9533 - accuracy: 0.6125 - val_loss: 0.9283 - val_accuracy: 0.6375\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9481 - accuracy: 0.6187 - val_loss: 0.9262 - val_accuracy: 0.6375\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9654 - accuracy: 0.6187 - val_loss: 0.9248 - val_accuracy: 0.6375\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9561 - accuracy: 0.6156 - val_loss: 0.9235 - val_accuracy: 0.6375\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9285 - accuracy: 0.6219 - val_loss: 0.9235 - val_accuracy: 0.6375\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9527 - accuracy: 0.6156 - val_loss: 0.9240 - val_accuracy: 0.6375\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9430 - accuracy: 0.6219 - val_loss: 0.9226 - val_accuracy: 0.6375\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9367 - accuracy: 0.6250 - val_loss: 0.9226 - val_accuracy: 0.6375\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9676 - accuracy: 0.6125 - val_loss: 0.9224 - val_accuracy: 0.6375\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9508 - accuracy: 0.6250 - val_loss: 0.9222 - val_accuracy: 0.6375\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9384 - accuracy: 0.6187 - val_loss: 0.9227 - val_accuracy: 0.6375\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9525 - accuracy: 0.6187 - val_loss: 0.9223 - val_accuracy: 0.6375\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9405 - accuracy: 0.6219 - val_loss: 0.9219 - val_accuracy: 0.6375\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9242 - accuracy: 0.6219 - val_loss: 0.9214 - val_accuracy: 0.6375\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9460 - accuracy: 0.6156 - val_loss: 0.9206 - val_accuracy: 0.6375\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9405 - accuracy: 0.6219 - val_loss: 0.9203 - val_accuracy: 0.6375\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9668 - accuracy: 0.6187 - val_loss: 0.9214 - val_accuracy: 0.6375\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9424 - accuracy: 0.6187 - val_loss: 0.9222 - val_accuracy: 0.6375\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9247 - accuracy: 0.6187 - val_loss: 0.9225 - val_accuracy: 0.6375\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9536 - accuracy: 0.6156 - val_loss: 0.9206 - val_accuracy: 0.6375\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9396 - accuracy: 0.6187 - val_loss: 0.9177 - val_accuracy: 0.6375\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9320 - accuracy: 0.6187 - val_loss: 0.9160 - val_accuracy: 0.6375\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9528 - accuracy: 0.6187 - val_loss: 0.9146 - val_accuracy: 0.6375\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.9319 - accuracy: 0.6187 - val_loss: 0.9142 - val_accuracy: 0.6375\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9512 - accuracy: 0.6187 - val_loss: 0.9138 - val_accuracy: 0.6375\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9408 - accuracy: 0.6187 - val_loss: 0.9134 - val_accuracy: 0.6375\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9483 - accuracy: 0.6187 - val_loss: 0.9133 - val_accuracy: 0.6375\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9468 - accuracy: 0.6187 - val_loss: 0.9133 - val_accuracy: 0.6375\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9464 - accuracy: 0.6187 - val_loss: 0.9132 - val_accuracy: 0.6375\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9396 - accuracy: 0.6187 - val_loss: 0.9130 - val_accuracy: 0.6375\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9508 - accuracy: 0.6187 - val_loss: 0.9129 - val_accuracy: 0.6375\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9465 - accuracy: 0.6187 - val_loss: 0.9125 - val_accuracy: 0.6375\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9517 - accuracy: 0.6125 - val_loss: 0.9129 - val_accuracy: 0.6375\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9443 - accuracy: 0.6187 - val_loss: 0.9134 - val_accuracy: 0.6375\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9343 - accuracy: 0.6219 - val_loss: 0.9150 - val_accuracy: 0.6375\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9242 - accuracy: 0.6187 - val_loss: 0.9160 - val_accuracy: 0.6375\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9322 - accuracy: 0.6156 - val_loss: 0.9165 - val_accuracy: 0.6375\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9368 - accuracy: 0.6187 - val_loss: 0.9169 - val_accuracy: 0.6375\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9357 - accuracy: 0.6187 - val_loss: 0.9180 - val_accuracy: 0.6375\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9286 - accuracy: 0.6187 - val_loss: 0.9185 - val_accuracy: 0.6375\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9474 - accuracy: 0.6187 - val_loss: 0.9184 - val_accuracy: 0.6375\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9261 - accuracy: 0.6187 - val_loss: 0.9189 - val_accuracy: 0.6375\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9426 - accuracy: 0.6187 - val_loss: 0.9204 - val_accuracy: 0.6375\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9481 - accuracy: 0.6187 - val_loss: 0.9226 - val_accuracy: 0.6375\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9350 - accuracy: 0.6187 - val_loss: 0.9240 - val_accuracy: 0.6375\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9353 - accuracy: 0.6187 - val_loss: 0.9238 - val_accuracy: 0.6375\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9257 - accuracy: 0.6187 - val_loss: 0.9235 - val_accuracy: 0.6375\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9198 - accuracy: 0.6187 - val_loss: 0.9234 - val_accuracy: 0.6375\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9315 - accuracy: 0.6187 - val_loss: 0.9249 - val_accuracy: 0.6375\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9370 - accuracy: 0.6187 - val_loss: 0.9271 - val_accuracy: 0.6375\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9252 - accuracy: 0.6062 - val_loss: 0.9279 - val_accuracy: 0.6375\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9273 - accuracy: 0.6187 - val_loss: 0.9292 - val_accuracy: 0.6375\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9269 - accuracy: 0.6187 - val_loss: 0.9310 - val_accuracy: 0.6375\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9432 - accuracy: 0.6187 - val_loss: 0.9317 - val_accuracy: 0.6375\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9284 - accuracy: 0.6187 - val_loss: 0.9329 - val_accuracy: 0.6375\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9150 - accuracy: 0.6187 - val_loss: 0.9338 - val_accuracy: 0.6375\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9388 - accuracy: 0.6187 - val_loss: 0.9337 - val_accuracy: 0.6375\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9526 - accuracy: 0.6156 - val_loss: 0.9323 - val_accuracy: 0.6375\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9252 - accuracy: 0.6187 - val_loss: 0.9301 - val_accuracy: 0.6375\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9194 - accuracy: 0.6187 - val_loss: 0.9276 - val_accuracy: 0.6375\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9358 - accuracy: 0.6187 - val_loss: 0.9252 - val_accuracy: 0.6375\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9295 - accuracy: 0.6187 - val_loss: 0.9237 - val_accuracy: 0.6375\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9279 - accuracy: 0.6187 - val_loss: 0.9213 - val_accuracy: 0.6375\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9363 - accuracy: 0.6187 - val_loss: 0.9193 - val_accuracy: 0.6375\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9255 - accuracy: 0.6187 - val_loss: 0.9175 - val_accuracy: 0.6375\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9371 - accuracy: 0.6187 - val_loss: 0.9160 - val_accuracy: 0.6375\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9256 - accuracy: 0.6187 - val_loss: 0.9142 - val_accuracy: 0.6375\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9301 - accuracy: 0.6187 - val_loss: 0.9130 - val_accuracy: 0.6375\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9395 - accuracy: 0.6187 - val_loss: 0.9122 - val_accuracy: 0.6375\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9352 - accuracy: 0.6187 - val_loss: 0.9129 - val_accuracy: 0.6375\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9392 - accuracy: 0.6187 - val_loss: 0.9136 - val_accuracy: 0.6375\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9308 - accuracy: 0.6187 - val_loss: 0.9146 - val_accuracy: 0.6375\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9236 - accuracy: 0.6187 - val_loss: 0.9162 - val_accuracy: 0.6375\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9219 - accuracy: 0.6187 - val_loss: 0.9161 - val_accuracy: 0.6375\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9279 - accuracy: 0.6187 - val_loss: 0.9167 - val_accuracy: 0.6375\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9455 - accuracy: 0.6187 - val_loss: 0.9178 - val_accuracy: 0.6375\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9456 - accuracy: 0.6187 - val_loss: 0.9187 - val_accuracy: 0.6375\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9498 - accuracy: 0.6187 - val_loss: 0.9193 - val_accuracy: 0.6375\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9236 - accuracy: 0.6187 - val_loss: 0.9195 - val_accuracy: 0.6375\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9477 - accuracy: 0.6187 - val_loss: 0.9208 - val_accuracy: 0.6375\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9349 - accuracy: 0.6187 - val_loss: 0.9214 - val_accuracy: 0.6375\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9264 - accuracy: 0.6187 - val_loss: 0.9212 - val_accuracy: 0.6375\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val,y_val) , batch_size=batch_size, epochs=epochs)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (last epoch): 0.6187\n",
      "Validation Accuracy (last epoch): 0.6375\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = history.history['accuracy']  # Training accuracy per epoch\n",
    "val_accuracy = history.history['val_accuracy']  # Validation accuracy per epoch\n",
    "\n",
    "print(f\"Training Accuracy (last epoch): {train_accuracy[-1]:.4f}\")\n",
    "print(f\"Validation Accuracy (last epoch): {val_accuracy[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 855us/step\n",
      "4/4 [==============================] - 0s 641us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict probabilities for test set\n",
    "y_test_cat = keras.utils.to_categorical(y_test, 3)\n",
    "y_pred = model.predict(x_test)\n",
    "# predict crisp classes for test set\n",
    "#yhat_classes = model.predict_classes(x_test)\n",
    "y_pred_probabilities = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "precision_scores = precision_score(y_test, y_pred, average=None)  # Get F1 for ALL classes\n",
    "precision_scores[0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the neural network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64,activation='relu',input_dim = x_train.shape[1]))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 100\n",
    "sdg_optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sdg_optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 332.0447 - accuracy: 0.3531 - val_loss: 30.6843 - val_accuracy: 0.6375\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 30.0166 - accuracy: 0.4625 - val_loss: 31.4737 - val_accuracy: 0.1750\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 33.4229 - accuracy: 0.3969 - val_loss: 8.1899 - val_accuracy: 0.1875\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.4228 - accuracy: 0.4500 - val_loss: 6.1804 - val_accuracy: 0.1750\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 3.6883 - accuracy: 0.2719 - val_loss: 1.0345 - val_accuracy: 0.6375\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0389 - accuracy: 0.6187 - val_loss: 1.0050 - val_accuracy: 0.6375\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.0171 - accuracy: 0.6187 - val_loss: 0.9777 - val_accuracy: 0.6375\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1.0215 - accuracy: 0.6187 - val_loss: 0.9664 - val_accuracy: 0.6375\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9845 - accuracy: 0.6187 - val_loss: 0.9454 - val_accuracy: 0.6375\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9686 - accuracy: 0.6187 - val_loss: 0.9305 - val_accuracy: 0.6375\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9635 - accuracy: 0.6187 - val_loss: 0.9246 - val_accuracy: 0.6375\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9574 - accuracy: 0.6187 - val_loss: 0.9381 - val_accuracy: 0.6375\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9567 - accuracy: 0.6187 - val_loss: 0.9236 - val_accuracy: 0.6375\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9575 - accuracy: 0.6187 - val_loss: 0.9161 - val_accuracy: 0.6375\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9449 - accuracy: 0.6187 - val_loss: 0.9135 - val_accuracy: 0.6375\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9438 - accuracy: 0.6187 - val_loss: 0.9114 - val_accuracy: 0.6375\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9419 - accuracy: 0.6187 - val_loss: 0.9195 - val_accuracy: 0.6375\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9419 - accuracy: 0.6187 - val_loss: 0.9085 - val_accuracy: 0.6375\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9408 - accuracy: 0.6187 - val_loss: 0.9084 - val_accuracy: 0.6375\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9400 - accuracy: 0.6187 - val_loss: 0.9095 - val_accuracy: 0.6375\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9397 - accuracy: 0.6187 - val_loss: 0.9093 - val_accuracy: 0.6375\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9399 - accuracy: 0.6187 - val_loss: 0.9134 - val_accuracy: 0.6375\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.9382 - accuracy: 0.6187 - val_loss: 0.9082 - val_accuracy: 0.6375\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.9397 - accuracy: 0.6187 - val_loss: 0.9180 - val_accuracy: 0.6375\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9429 - accuracy: 0.6187 - val_loss: 0.9263 - val_accuracy: 0.6375\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9430 - accuracy: 0.6187 - val_loss: 0.9086 - val_accuracy: 0.6375\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9414 - accuracy: 0.6187 - val_loss: 0.9163 - val_accuracy: 0.6375\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9395 - accuracy: 0.6187 - val_loss: 0.9115 - val_accuracy: 0.6375\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9375 - accuracy: 0.6187 - val_loss: 0.9094 - val_accuracy: 0.6375\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9374 - accuracy: 0.6187 - val_loss: 0.9172 - val_accuracy: 0.6375\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9436 - accuracy: 0.6187 - val_loss: 0.9189 - val_accuracy: 0.6375\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9414 - accuracy: 0.6187 - val_loss: 0.9116 - val_accuracy: 0.6375\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9378 - accuracy: 0.6187 - val_loss: 0.9115 - val_accuracy: 0.6375\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9399 - accuracy: 0.6187 - val_loss: 0.9089 - val_accuracy: 0.6375\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9386 - accuracy: 0.6187 - val_loss: 0.9074 - val_accuracy: 0.6375\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9381 - accuracy: 0.6187 - val_loss: 0.9073 - val_accuracy: 0.6375\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9384 - accuracy: 0.6187 - val_loss: 0.9073 - val_accuracy: 0.6375\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9390 - accuracy: 0.6187 - val_loss: 0.9084 - val_accuracy: 0.6375\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9358 - accuracy: 0.6187 - val_loss: 0.9195 - val_accuracy: 0.6375\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9343 - accuracy: 0.6187 - val_loss: 0.9177 - val_accuracy: 0.6375\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9362 - accuracy: 0.6187 - val_loss: 0.9151 - val_accuracy: 0.6375\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9499 - accuracy: 0.6187 - val_loss: 0.9076 - val_accuracy: 0.6375\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9387 - accuracy: 0.6187 - val_loss: 0.9095 - val_accuracy: 0.6375\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9399 - accuracy: 0.6187 - val_loss: 0.9081 - val_accuracy: 0.6375\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9375 - accuracy: 0.6187 - val_loss: 0.9075 - val_accuracy: 0.6375\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9367 - accuracy: 0.6187 - val_loss: 0.9122 - val_accuracy: 0.6375\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9376 - accuracy: 0.6187 - val_loss: 0.9067 - val_accuracy: 0.6375\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9375 - accuracy: 0.6187 - val_loss: 0.9068 - val_accuracy: 0.6375\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9368 - accuracy: 0.6187 - val_loss: 0.9080 - val_accuracy: 0.6375\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9386 - accuracy: 0.6187 - val_loss: 0.9088 - val_accuracy: 0.6375\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9367 - accuracy: 0.6187 - val_loss: 0.9108 - val_accuracy: 0.6375\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9399 - accuracy: 0.6187 - val_loss: 0.9265 - val_accuracy: 0.6375\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9426 - accuracy: 0.6187 - val_loss: 0.9076 - val_accuracy: 0.6375\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9397 - accuracy: 0.6187 - val_loss: 0.9088 - val_accuracy: 0.6375\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9418 - accuracy: 0.6187 - val_loss: 0.9067 - val_accuracy: 0.6375\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9412 - accuracy: 0.6187 - val_loss: 0.9072 - val_accuracy: 0.6375\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9415 - accuracy: 0.6187 - val_loss: 0.9078 - val_accuracy: 0.6375\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9377 - accuracy: 0.6187 - val_loss: 0.9118 - val_accuracy: 0.6375\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9343 - accuracy: 0.6187 - val_loss: 0.9145 - val_accuracy: 0.6375\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9344 - accuracy: 0.6187 - val_loss: 0.9982 - val_accuracy: 0.6375\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9766 - accuracy: 0.6187 - val_loss: 0.9072 - val_accuracy: 0.6375\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9394 - accuracy: 0.6187 - val_loss: 0.9071 - val_accuracy: 0.6375\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9440 - accuracy: 0.6187 - val_loss: 0.9078 - val_accuracy: 0.6375\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9415 - accuracy: 0.6187 - val_loss: 0.9097 - val_accuracy: 0.6375\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9416 - accuracy: 0.6187 - val_loss: 0.9070 - val_accuracy: 0.6375\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9385 - accuracy: 0.6187 - val_loss: 0.9083 - val_accuracy: 0.6375\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9382 - accuracy: 0.6187 - val_loss: 0.9072 - val_accuracy: 0.6375\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9381 - accuracy: 0.6187 - val_loss: 0.9122 - val_accuracy: 0.6375\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9394 - accuracy: 0.6187 - val_loss: 0.9106 - val_accuracy: 0.6375\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9394 - accuracy: 0.6187 - val_loss: 0.9078 - val_accuracy: 0.6375\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9397 - accuracy: 0.6187 - val_loss: 0.9079 - val_accuracy: 0.6375\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9401 - accuracy: 0.6187 - val_loss: 0.9071 - val_accuracy: 0.6375\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9374 - accuracy: 0.6187 - val_loss: 0.9116 - val_accuracy: 0.6375\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9372 - accuracy: 0.6187 - val_loss: 0.9078 - val_accuracy: 0.6375\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9384 - accuracy: 0.6187 - val_loss: 0.9078 - val_accuracy: 0.6375\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9393 - accuracy: 0.6187 - val_loss: 0.9077 - val_accuracy: 0.6375\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9391 - accuracy: 0.6187 - val_loss: 0.9105 - val_accuracy: 0.6375\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9375 - accuracy: 0.6187 - val_loss: 0.9087 - val_accuracy: 0.6375\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9364 - accuracy: 0.6187 - val_loss: 0.9084 - val_accuracy: 0.6375\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9369 - accuracy: 0.6187 - val_loss: 0.9075 - val_accuracy: 0.6375\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9393 - accuracy: 0.6187 - val_loss: 0.9076 - val_accuracy: 0.6375\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9391 - accuracy: 0.6187 - val_loss: 0.9106 - val_accuracy: 0.6375\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9385 - accuracy: 0.6187 - val_loss: 0.9131 - val_accuracy: 0.6375\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9448 - accuracy: 0.6187 - val_loss: 0.9179 - val_accuracy: 0.6375\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9368 - accuracy: 0.6187 - val_loss: 0.9146 - val_accuracy: 0.6375\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9385 - accuracy: 0.6187 - val_loss: 0.9324 - val_accuracy: 0.6375\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9623 - accuracy: 0.6187 - val_loss: 0.9069 - val_accuracy: 0.6375\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9418 - accuracy: 0.6187 - val_loss: 0.9073 - val_accuracy: 0.6375\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9406 - accuracy: 0.6187 - val_loss: 0.9205 - val_accuracy: 0.6375\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9423 - accuracy: 0.6187 - val_loss: 0.9117 - val_accuracy: 0.6375\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9388 - accuracy: 0.6187 - val_loss: 0.9073 - val_accuracy: 0.6375\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9384 - accuracy: 0.6187 - val_loss: 0.9073 - val_accuracy: 0.6375\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9387 - accuracy: 0.6187 - val_loss: 0.9094 - val_accuracy: 0.6375\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9452 - accuracy: 0.6187 - val_loss: 0.9092 - val_accuracy: 0.6375\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9400 - accuracy: 0.6187 - val_loss: 0.9106 - val_accuracy: 0.6375\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9391 - accuracy: 0.6187 - val_loss: 0.9074 - val_accuracy: 0.6375\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9381 - accuracy: 0.6187 - val_loss: 0.9112 - val_accuracy: 0.6375\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9394 - accuracy: 0.6187 - val_loss: 0.9162 - val_accuracy: 0.6375\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9408 - accuracy: 0.6187 - val_loss: 0.9121 - val_accuracy: 0.6375\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9371 - accuracy: 0.6187 - val_loss: 0.9080 - val_accuracy: 0.6375\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val,y_val) , batch_size=batch_size, epochs=epochs)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 592us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5632211 , 0.22543228, 0.2113466 ],\n",
       "       [0.623396  , 0.19615857, 0.18044552],\n",
       "       [0.6239757 , 0.19587423, 0.1801501 ],\n",
       "       [0.62922835, 0.19329593, 0.17747577],\n",
       "       [0.6206337 , 0.19751279, 0.18185353],\n",
       "       [0.63004583, 0.19289431, 0.17705986],\n",
       "       [0.62232906, 0.19668174, 0.1809892 ],\n",
       "       [0.6280796 , 0.19386007, 0.17806034],\n",
       "       [0.62423646, 0.19574627, 0.18001728],\n",
       "       [0.57092464, 0.2217117 , 0.2073636 ],\n",
       "       [0.6280796 , 0.19386007, 0.17806034],\n",
       "       [0.6247029 , 0.19551747, 0.17977971],\n",
       "       [0.5624061 , 0.22582544, 0.21176845],\n",
       "       [0.6214589 , 0.19710833, 0.18143277],\n",
       "       [0.62132   , 0.19717637, 0.18150358],\n",
       "       [0.5782459 , 0.2187049 , 0.20304926],\n",
       "       [0.6263946 , 0.19468732, 0.1789181 ],\n",
       "       [0.56706446, 0.22357707, 0.20935845],\n",
       "       [0.62081397, 0.19742443, 0.1817616 ],\n",
       "       [0.61918336, 0.19822343, 0.18259323],\n",
       "       [0.62922835, 0.19329593, 0.17747577],\n",
       "       [0.6210126 , 0.19732708, 0.18166037],\n",
       "       [0.5652484 , 0.22445396, 0.21029764],\n",
       "       [0.6206337 , 0.19751279, 0.18185353],\n",
       "       [0.5920718 , 0.2114571 , 0.19647114],\n",
       "       [0.62150466, 0.1970859 , 0.18140948],\n",
       "       [0.5701583 , 0.22208221, 0.20775948],\n",
       "       [0.63666517, 0.1896394 , 0.17369543],\n",
       "       [0.6174089 , 0.19909261, 0.18349864],\n",
       "       [0.62009776, 0.19777545, 0.18212683],\n",
       "       [0.63541967, 0.19025226, 0.17432804],\n",
       "       [0.56585556, 0.22416086, 0.20998363],\n",
       "       [0.6284099 , 0.19369785, 0.17789218],\n",
       "       [0.61853415, 0.19854149, 0.18292445],\n",
       "       [0.6210126 , 0.19732708, 0.18166037],\n",
       "       [0.62350273, 0.19610617, 0.18039107],\n",
       "       [0.6231527 , 0.19627786, 0.18056947],\n",
       "       [0.6205903 , 0.19753402, 0.18187563],\n",
       "       [0.6177704 , 0.19891554, 0.18331411],\n",
       "       [0.56792516, 0.22316131, 0.20891349],\n",
       "       [0.5726871 , 0.22085938, 0.20645353],\n",
       "       [0.56666905, 0.22376804, 0.20956293],\n",
       "       [0.6296214 , 0.19310282, 0.17727579],\n",
       "       [0.6210126 , 0.19732708, 0.18166037],\n",
       "       [0.6202508 , 0.1977004 , 0.18204874],\n",
       "       [0.63456196, 0.19067422, 0.17476384],\n",
       "       [0.6222398 , 0.19672547, 0.18103471],\n",
       "       [0.6166754 , 0.19945166, 0.18387295],\n",
       "       [0.5710175 , 0.22166681, 0.20731567],\n",
       "       [0.62232906, 0.19668174, 0.1809892 ],\n",
       "       [0.61644787, 0.19956304, 0.1839891 ],\n",
       "       [0.62759095, 0.1941    , 0.178309  ],\n",
       "       [0.6025833 , 0.23540059, 0.16201608],\n",
       "       [0.62595075, 0.19490515, 0.17914407],\n",
       "       [0.62150466, 0.1970859 , 0.18140948],\n",
       "       [0.6267713 , 0.19450247, 0.17872635],\n",
       "       [0.6288096 , 0.19350159, 0.17768879],\n",
       "       [0.61859787, 0.19851027, 0.18289194],\n",
       "       [0.6222337 , 0.19672851, 0.18103783],\n",
       "       [0.62018716, 0.19773161, 0.18208127],\n",
       "       [0.576164  , 0.21917665, 0.20465928],\n",
       "       [0.62479794, 0.19547088, 0.17973128],\n",
       "       [0.6251041 , 0.19532059, 0.17957526],\n",
       "       [0.6209234 , 0.19737081, 0.1817058 ],\n",
       "       [0.62018716, 0.19773161, 0.18208127],\n",
       "       [0.61727643, 0.19915736, 0.18356614],\n",
       "       [0.6222337 , 0.19672851, 0.18103783],\n",
       "       [0.6279849 , 0.19390662, 0.17810857],\n",
       "       [0.61580604, 0.19987722, 0.18431675],\n",
       "       [0.6218375 , 0.19692273, 0.1812398 ],\n",
       "       [0.56929857, 0.22249773, 0.20820367],\n",
       "       [0.6227252 , 0.1964875 , 0.18078732],\n",
       "       [0.61840737, 0.2290722 , 0.15252042],\n",
       "       [0.62479794, 0.19547088, 0.17973128],\n",
       "       [0.6243075 , 0.1957114 , 0.17998105],\n",
       "       [0.6259685 , 0.19489644, 0.17913507],\n",
       "       [0.6218375 , 0.19692273, 0.1812398 ],\n",
       "       [0.6247522 , 0.19549327, 0.17975451],\n",
       "       [0.5744504 , 0.22000623, 0.20554343],\n",
       "       [0.62348485, 0.19611494, 0.18040018],\n",
       "       [0.59337074, 0.2161172 , 0.19051206],\n",
       "       [0.6177065 , 0.1989468 , 0.18334675],\n",
       "       [0.6238806 , 0.19592081, 0.18019855],\n",
       "       [0.5701583 , 0.22208221, 0.20775948],\n",
       "       [0.61853415, 0.19854149, 0.18292445],\n",
       "       [0.62058413, 0.19753708, 0.1818788 ],\n",
       "       [0.61853415, 0.19854149, 0.18292445],\n",
       "       [0.6263946 , 0.19468732, 0.1789181 ],\n",
       "       [0.61985373, 0.19789496, 0.18225127],\n",
       "       [0.5831106 , 0.21858127, 0.19830818],\n",
       "       [0.61985373, 0.19789496, 0.18225127],\n",
       "       [0.620205  , 0.19772288, 0.18207215],\n",
       "       [0.56447965, 0.22482501, 0.21069534],\n",
       "       [0.62150466, 0.1970859 , 0.18140948],\n",
       "       [0.5627544 , 0.2256574 , 0.21158814],\n",
       "       [0.6279849 , 0.19390662, 0.17810857],\n",
       "       [0.61701894, 0.1992835 , 0.18369763],\n",
       "       [0.57565325, 0.21942396, 0.20492283],\n",
       "       [0.6297159 , 0.19305636, 0.17722768],\n",
       "       [0.56671697, 0.22374491, 0.20953816]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "# predict crisp classes for test set\n",
    "#yhat_classes = model.predict_classes(x_test)\n",
    "y_pred_probabilities = model.predict(x_test)\n",
    "y_pred_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_final_2=[]\n",
    "for i in y_pred:\n",
    " y_pred_final_2.append(np.argmax(i))\n",
    "y_pred_final_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.68        51\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.51       100\n",
      "   macro avg       0.17      0.33      0.23       100\n",
      "weighted avg       0.26      0.51      0.34       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred_final_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "W_Ho8VGKDu3S",
    "9d5QE-n57qf9",
    "xxhpZv9y-qTw",
    "_ruS1OQwB_fX",
    "qlzqMR1K-qTz",
    "KQi5ygTC-qT1",
    "wBplxfQ5L2VQ",
    "5TcqcxbK-qT3",
    "xNr4bWoM-qT5",
    "2_2JAlQoAYGv",
    "kUJ_B5KxhU3D",
    "9nu28gwqexqz",
    "HdlR3wVEMyfW",
    "s7MRxT3t7qga",
    "k3uJz1M5Ftfs",
    "qL4SMFui7qge",
    "NE2JV7LD7qgf",
    "mqV9hRi9MoKW",
    "VKRHs0BHFMz6",
    "ONKpeUbX7qgg",
    "LUrktk3s7qgP",
    "BUM8wCaH7qgh",
    "mJM22vsN7qgQ",
    "DJRpa_ITr_hP",
    "KfNstwe1iXll",
    "Rrj0G84NkC02",
    "eU_yWERC7qgQ",
    "AdJrTn9P7WkF",
    "ikcCDMEc-wzw",
    "cA5l4TVkj15W",
    "gR-rFzZIPN-o",
    "fEydOFEMhh84",
    "i-APFNHKiXsi",
    "FpHMzrg2L_MU",
    "F_WtTUilipXj",
    "l2qk2QLoj8sJ",
    "mTxi2rzOkE5j",
    "Eyyes8dpkQUr",
    "gv4MGa9-16LM",
    "gwBcwQmT2Ngg",
    "T2GolnQVHC4-",
    "D2eFxAmjC-PS",
    "tdDYbUXH7qga",
    "lLXVWxH47qgc",
    "GPKdwqGw7qgc",
    "PHqiu-HX7qgd",
    "-_NuZlBm7qgd",
    "ipUkvSwz7qgd",
    "sG7mxmsh7qge",
    "-ChY-dfR7qge",
    "OsIgJ04R7qge",
    "_iInaZLs7qgg",
    "nEDRlDTm7qgg",
    "OT2yi77m7qgQ",
    "QzE4NOLn7qgQ",
    "l5-C4x7Q7qgh",
    "y5Vqlehz7qgh",
    "SHL5A6fn7qgh",
    "_qCaiIBc7qgi",
    "MBHhnjDCljw-"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
